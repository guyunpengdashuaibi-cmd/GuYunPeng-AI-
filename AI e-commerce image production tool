import streamlit as st
import google.generativeai as genai

# 1. é¡µé¢åŸºæœ¬é…ç½®
st.set_page_config(page_title="AI åŠ©æ‰‹ (BYOKç‰ˆ)", page_icon="ğŸ¤–")
st.title("ğŸ¤– è·Ÿæˆ‘åˆ¶ä½œçš„ AI èŠèŠ")

# 2. ä¾§è¾¹æ ï¼šè®©æœ‹å‹è¾“å…¥è‡ªå·±çš„ API Key
with st.sidebar:
    st.header("ğŸ”‘ èº«ä»½éªŒè¯")
    st.markdown("""
    ä¸ºäº†ä½¿ç”¨æ­¤å·¥å…·ï¼Œä½ éœ€è¦è¾“å…¥è‡ªå·±çš„ Google API Keyã€‚
    
    [ğŸ‘‰ ç‚¹å‡»è¿™é‡Œå…è´¹è·å– Key](https://aistudio.google.com/app/apikey)
    """)
    # type="password" å¯ä»¥è®©è¾“å…¥çš„å­—ç¬¦å˜æˆåœ†ç‚¹ï¼Œä¿æŠ¤éšç§
    user_api_key = st.text_input("è¯·è¾“å…¥ä½ çš„ API Key", type="password")

# 3. æ£€æŸ¥æ˜¯å¦è¾“å…¥äº† Key
if not user_api_key:
    st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ä½ çš„ Google API Key æ‰èƒ½å¼€å§‹å¯¹è¯ã€‚")
    st.stop() # åœæ­¢è¿è¡Œä¸‹é¢çš„ä»£ç ï¼Œç›´åˆ°ç”¨æˆ·è¾“å…¥ Key

# 4. é…ç½® Google Gemini (ä½¿ç”¨æœ‹å‹çš„ Key)
try:
    genai.configure(api_key=user_api_key)
    # ç®€å•æµ‹è¯•ä¸€ä¸‹ Key æ˜¯å¦æœ‰æ•ˆ
    model = genai.GenerativeModel('gemini-pro')
except Exception as e:
    st.error(f"API Key è®¾ç½®æœ‰è¯¯ï¼Œè¯·æ£€æŸ¥: {e}")
    st.stop()

# --- ä»¥ä¸‹æ˜¯èŠå¤©é€»è¾‘ (å’Œä¹‹å‰ä¸€æ ·) ---

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("è¾“å…¥ä½ æƒ³è¯´çš„è¯..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        try:
            chat = model.start_chat(history=[
                {"role": m["role"], "parts": [m["content"]]} 
                for m in st.session_state.messages[:-1]
            ])
            response = chat.send_message(prompt, stream=True)
            
            # ç®€å•çš„æµå¼è¾“å‡ºæ•ˆæœ
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
            
            st.session_state.messages.append({"role": "model", "content": full_response})
        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯ (å¯èƒ½æ˜¯ç½‘ç»œæˆ–Keyçš„é—®é¢˜): {e}")
